{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NCF.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JGPplZhlERQI",
        "i7GGqxeWEPst",
        "XnF2Ec-WERsH",
        "ln_GIs7fERyv",
        "syH7woQyER6I"
      ],
      "authorship_tag": "ABX9TyOob+YvSktcKby3UUFtWd68",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aSafarpoor/Recommender_Systems/blob/main/NCF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xWA3r-J5EGVY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A pytorch GPU implementation of He et al. \"Neural Collaborative Filtering**\n",
        "\n",
        "based on https://github.com/hexiangnan/neural_collaborative_filtering"
      ],
      "metadata": {
        "id": "mjR8QG53EIV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=256 \n",
        "lr=0.001 \n",
        "factor_num=16"
      ],
      "metadata": {
        "id": "gYOCOuSuEYcc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "JGPplZhlERQI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5hjb4XKNERQJ"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    def __init__(self):\n",
        "        # dataset name \n",
        "        dataset = 'ml-1m'\n",
        "        assert dataset in ['ml-1m', 'pinterest-20']\n",
        "\n",
        "        # model name \n",
        "        model = 'NeuMF-end'\n",
        "        assert model in ['MLP', 'GMF', 'NeuMF-end', 'NeuMF-pre']\n",
        "\n",
        "        # paths\n",
        "        main_path = '/home/share/guoyangyang/recommendation/NCF-Data/'\n",
        "\n",
        "        train_rating = main_path + '{}.train.rating'.format(dataset)\n",
        "        test_rating = main_path + '{}.test.rating'.format(dataset)\n",
        "        test_negative = main_path + '{}.test.negative'.format(dataset)\n",
        "\n",
        "        model_path = './models/'\n",
        "        GMF_model_path = model_path + 'GMF.pth'\n",
        "        MLP_model_path = model_path + 'MLP.pth'\n",
        "        NeuMF_model_path = model_path + 'NeuMF.pth'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data utils:"
      ],
      "metadata": {
        "id": "i7GGqxeWEPst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import scipy.sparse as sp\n",
        "import torch.utils.data as data\n",
        "\n",
        "config = Config()"
      ],
      "metadata": {
        "id": "_K5nnQQbEwP9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vJWxhjDBEC7j"
      },
      "outputs": [],
      "source": [
        "def load_all(test_num=100):\n",
        "\t\"\"\" We load all the three file here to save time in each epoch. \"\"\"\n",
        "\ttrain_data = pd.read_csv(\n",
        "\t\tconfig.train_rating, \n",
        "\t\tsep='\\t', header=None, names=['user', 'item'], \n",
        "\t\tusecols=[0, 1], dtype={0: np.int32, 1: np.int32})\n",
        "\n",
        "\tuser_num = train_data['user'].max() + 1\n",
        "\titem_num = train_data['item'].max() + 1\n",
        "\n",
        "\ttrain_data = train_data.values.tolist()\n",
        "\n",
        "\t# load ratings as a dok matrix\n",
        "\ttrain_mat = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n",
        "\tfor x in train_data:\n",
        "\t\ttrain_mat[x[0], x[1]] = 1.0\n",
        "\n",
        "\ttest_data = []\n",
        "\twith open(config.test_negative, 'r') as fd:\n",
        "\t\tline = fd.readline()\n",
        "\t\twhile line != None and line != '':\n",
        "\t\t\tarr = line.split('\\t')\n",
        "\t\t\tu = eval(arr[0])[0]\n",
        "\t\t\ttest_data.append([u, eval(arr[0])[1]])\n",
        "\t\t\tfor i in arr[1:]:\n",
        "\t\t\t\ttest_data.append([u, int(i)])\n",
        "\t\t\tline = fd.readline()\n",
        "\treturn train_data, test_data, user_num, item_num, train_mat\t\t"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NCFData(data.Dataset):\n",
        "\tdef __init__(self, features, \n",
        "\t\t\t\tnum_item, train_mat=None, num_ng=0, is_training=None):\n",
        "\t\tsuper(NCFData, self).__init__()\n",
        "\t\t\"\"\" Note that the labels are only useful when training, we thus \n",
        "\t\t\tadd them in the ng_sample() function.\n",
        "\t\t\"\"\"\n",
        "\t\tself.features_ps = features\n",
        "\t\tself.num_item = num_item\n",
        "\t\tself.train_mat = train_mat\n",
        "\t\tself.num_ng = num_ng\n",
        "\t\tself.is_training = is_training\n",
        "\t\tself.labels = [0 for _ in range(len(features))]\n",
        "\n",
        "\tdef ng_sample(self):\n",
        "\t\tassert self.is_training, 'no need to sampling when testing'\n",
        "\n",
        "\t\tself.features_ng = []\n",
        "\t\tfor x in self.features_ps:\n",
        "\t\t\tu = x[0]\n",
        "\t\t\tfor t in range(self.num_ng):\n",
        "\t\t\t\tj = np.random.randint(self.num_item)\n",
        "\t\t\t\twhile (u, j) in self.train_mat:\n",
        "\t\t\t\t\tj = np.random.randint(self.num_item)\n",
        "\t\t\t\tself.features_ng.append([u, j])\n",
        "\n",
        "\t\tlabels_ps = [1 for _ in range(len(self.features_ps))]\n",
        "\t\tlabels_ng = [0 for _ in range(len(self.features_ng))]\n",
        "\n",
        "\t\tself.features_fill = self.features_ps + self.features_ng\n",
        "\t\tself.labels_fill = labels_ps + labels_ng\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn (self.num_ng + 1) * len(self.labels)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\tfeatures = self.features_fill if self.is_training \\\n",
        "\t\t\t\t\telse self.features_ps\n",
        "\t\tlabels = self.labels_fill if self.is_training \\\n",
        "\t\t\t\t\telse self.labels\n",
        "\n",
        "\t\tuser = features[idx][0]\n",
        "\t\titem = features[idx][1]\n",
        "\t\tlabel = labels[idx]\n",
        "\t\treturn user, item ,label"
      ],
      "metadata": {
        "id": "LluptRhWEs8f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evaluate"
      ],
      "metadata": {
        "id": "XnF2Ec-WERsH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ma3QT0QERsH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hit(gt_item, pred_items):\n",
        "\tif gt_item in pred_items:\n",
        "\t\treturn 1\n",
        "\treturn 0"
      ],
      "metadata": {
        "id": "vGAPohD6FhR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ndcg(gt_item, pred_items):\n",
        "\tif gt_item in pred_items:\n",
        "\t\tindex = pred_items.index(gt_item)\n",
        "\t\treturn np.reciprocal(np.log2(index+2))\n",
        "\treturn 0"
      ],
      "metadata": {
        "id": "hefpe2e0FfwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics(model, test_loader, top_k):\n",
        "\tHR, NDCG = [], []\n",
        "\n",
        "\tfor user, item, label in test_loader:\n",
        "\t\tuser = user.cuda()\n",
        "\t\titem = item.cuda()\n",
        "\n",
        "\t\tpredictions = model(user, item)\n",
        "\t\t_, indices = torch.topk(predictions, top_k)\n",
        "\t\trecommends = torch.take(\n",
        "\t\t\t\titem, indices).cpu().numpy().tolist()\n",
        "\n",
        "\t\tgt_item = item[0].item()\n",
        "\t\tHR.append(hit(gt_item, recommends))\n",
        "\t\tNDCG.append(ndcg(gt_item, recommends))\n",
        "\n",
        "\treturn np.mean(HR), np.mean(NDCG)"
      ],
      "metadata": {
        "id": "7YIUo7UlFeRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model:"
      ],
      "metadata": {
        "id": "ln_GIs7fERyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F "
      ],
      "metadata": {
        "id": "xpv0yz40Frdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbgu4dRCERyv"
      },
      "outputs": [],
      "source": [
        "class NCF(nn.Module):\n",
        "\tdef __init__(self, user_num, item_num, factor_num, num_layers,\n",
        "\t\t\t\t\tdropout, model, GMF_model=None, MLP_model=None):\n",
        "\t\tsuper(NCF, self).__init__()\n",
        "\t\t\"\"\"\n",
        "\t\tuser_num: number of users;\n",
        "\t\titem_num: number of items;\n",
        "\t\tfactor_num: number of predictive factors;\n",
        "\t\tnum_layers: the number of layers in MLP model;\n",
        "\t\tdropout: dropout rate between fully connected layers;\n",
        "\t\tmodel: 'MLP', 'GMF', 'NeuMF-end', and 'NeuMF-pre';\n",
        "\t\tGMF_model: pre-trained GMF weights;\n",
        "\t\tMLP_model: pre-trained MLP weights.\n",
        "\t\t\"\"\"\t\t\n",
        "\t\tself.dropout = dropout\n",
        "\t\tself.model = model\n",
        "\t\tself.GMF_model = GMF_model\n",
        "\t\tself.MLP_model = MLP_model\n",
        "\n",
        "\t\tself.embed_user_GMF = nn.Embedding(user_num, factor_num)\n",
        "\t\tself.embed_item_GMF = nn.Embedding(item_num, factor_num)\n",
        "\t\tself.embed_user_MLP = nn.Embedding(\n",
        "\t\t\t\tuser_num, factor_num * (2 ** (num_layers - 1)))\n",
        "\t\tself.embed_item_MLP = nn.Embedding(\n",
        "\t\t\t\titem_num, factor_num * (2 ** (num_layers - 1)))\n",
        "\n",
        "\t\tMLP_modules = []\n",
        "\t\tfor i in range(num_layers):\n",
        "\t\t\tinput_size = factor_num * (2 ** (num_layers - i))\n",
        "\t\t\tMLP_modules.append(nn.Dropout(p=self.dropout))\n",
        "\t\t\tMLP_modules.append(nn.Linear(input_size, input_size//2))\n",
        "\t\t\tMLP_modules.append(nn.ReLU())\n",
        "\t\tself.MLP_layers = nn.Sequential(*MLP_modules)\n",
        "\n",
        "\t\tif self.model in ['MLP', 'GMF']:\n",
        "\t\t\tpredict_size = factor_num \n",
        "\t\telse:\n",
        "\t\t\tpredict_size = factor_num * 2\n",
        "\t\tself.predict_layer = nn.Linear(predict_size, 1)\n",
        "\n",
        "\t\tself._init_weight_()\n",
        "\n",
        "\tdef _init_weight_(self):\n",
        "\t\t\"\"\" We leave the weights initialization here. \"\"\"\n",
        "\t\tif not self.model == 'NeuMF-pre':\n",
        "\t\t\tnn.init.normal_(self.embed_user_GMF.weight, std=0.01)\n",
        "\t\t\tnn.init.normal_(self.embed_user_MLP.weight, std=0.01)\n",
        "\t\t\tnn.init.normal_(self.embed_item_GMF.weight, std=0.01)\n",
        "\t\t\tnn.init.normal_(self.embed_item_MLP.weight, std=0.01)\n",
        "\n",
        "\t\t\tfor m in self.MLP_layers:\n",
        "\t\t\t\tif isinstance(m, nn.Linear):\n",
        "\t\t\t\t\tnn.init.xavier_uniform_(m.weight)\n",
        "\t\t\tnn.init.kaiming_uniform_(self.predict_layer.weight, \n",
        "\t\t\t\t\t\t\t\t\ta=1, nonlinearity='sigmoid')\n",
        "\n",
        "\t\t\tfor m in self.modules():\n",
        "\t\t\t\tif isinstance(m, nn.Linear) and m.bias is not None:\n",
        "\t\t\t\t\tm.bias.data.zero_()\n",
        "\t\telse:\n",
        "\t\t\t# embedding layers\n",
        "\t\t\tself.embed_user_GMF.weight.data.copy_(\n",
        "\t\t\t\t\t\t\tself.GMF_model.embed_user_GMF.weight)\n",
        "\t\t\tself.embed_item_GMF.weight.data.copy_(\n",
        "\t\t\t\t\t\t\tself.GMF_model.embed_item_GMF.weight)\n",
        "\t\t\tself.embed_user_MLP.weight.data.copy_(\n",
        "\t\t\t\t\t\t\tself.MLP_model.embed_user_MLP.weight)\n",
        "\t\t\tself.embed_item_MLP.weight.data.copy_(\n",
        "\t\t\t\t\t\t\tself.MLP_model.embed_item_MLP.weight)\n",
        "\n",
        "\t\t\t# mlp layers\n",
        "\t\t\tfor (m1, m2) in zip(\n",
        "\t\t\t\tself.MLP_layers, self.MLP_model.MLP_layers):\n",
        "\t\t\t\tif isinstance(m1, nn.Linear) and isinstance(m2, nn.Linear):\n",
        "\t\t\t\t\tm1.weight.data.copy_(m2.weight)\n",
        "\t\t\t\t\tm1.bias.data.copy_(m2.bias)\n",
        "\n",
        "\t\t\t# predict layers\n",
        "\t\t\tpredict_weight = torch.cat([\n",
        "\t\t\t\tself.GMF_model.predict_layer.weight, \n",
        "\t\t\t\tself.MLP_model.predict_layer.weight], dim=1)\n",
        "\t\t\tprecit_bias = self.GMF_model.predict_layer.bias + \\\n",
        "\t\t\t\t\t\tself.MLP_model.predict_layer.bias\n",
        "\n",
        "\t\t\tself.predict_layer.weight.data.copy_(0.5 * predict_weight)\n",
        "\t\t\tself.predict_layer.bias.data.copy_(0.5 * precit_bias)\n",
        "\n",
        "\tdef forward(self, user, item):\n",
        "\t\tif not self.model == 'MLP':\n",
        "\t\t\tembed_user_GMF = self.embed_user_GMF(user)\n",
        "\t\t\tembed_item_GMF = self.embed_item_GMF(item)\n",
        "\t\t\toutput_GMF = embed_user_GMF * embed_item_GMF\n",
        "\t\tif not self.model == 'GMF':\n",
        "\t\t\tembed_user_MLP = self.embed_user_MLP(user)\n",
        "\t\t\tembed_item_MLP = self.embed_item_MLP(item)\n",
        "\t\t\tinteraction = torch.cat((embed_user_MLP, embed_item_MLP), -1)\n",
        "\t\t\toutput_MLP = self.MLP_layers(interaction)\n",
        "\n",
        "\t\tif self.model == 'GMF':\n",
        "\t\t\tconcat = output_GMF\n",
        "\t\telif self.model == 'MLP':\n",
        "\t\t\tconcat = output_MLP\n",
        "\t\telse:\n",
        "\t\t\tconcat = torch.cat((output_GMF, output_MLP), -1)\n",
        "\n",
        "\t\tprediction = self.predict_layer(concat)\n",
        "\t\treturn prediction.view(-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main:"
      ],
      "metadata": {
        "id": "syH7woQyER6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJDoSTGnHBML",
        "outputId": "a4666eb5-045b-4132-f6c2-0cd8a7e28719"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.backends.cudnn as cudnn\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "'''\n",
        "import model\n",
        "import config\n",
        "import evaluate\n",
        "import data_utils\n",
        "'''"
      ],
      "metadata": {
        "id": "rcDqF9S2Fz5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--lr\", \n",
        "\ttype=float, \n",
        "\tdefault=0.001, \n",
        "\thelp=\"learning rate\")\n",
        "parser.add_argument(\"--dropout\", \n",
        "\ttype=float,\n",
        "\tdefault=0.0,  \n",
        "\thelp=\"dropout rate\")\n",
        "parser.add_argument(\"--batch_size\", \n",
        "\ttype=int, \n",
        "\tdefault=256, \n",
        "\thelp=\"batch size for training\")\n",
        "parser.add_argument(\"--epochs\", \n",
        "\ttype=int,\n",
        "\tdefault=20,  \n",
        "\thelp=\"training epoches\")\n",
        "parser.add_argument(\"--top_k\", \n",
        "\ttype=int, \n",
        "\tdefault=10, \n",
        "\thelp=\"compute metrics@top_k\")\n",
        "parser.add_argument(\"--factor_num\", \n",
        "\ttype=int,\n",
        "\tdefault=32, \n",
        "\thelp=\"predictive factors numbers in the model\")\n",
        "parser.add_argument(\"--num_layers\", \n",
        "\ttype=int,\n",
        "\tdefault=3, \n",
        "\thelp=\"number of layers in MLP model\")\n",
        "parser.add_argument(\"--num_ng\", \n",
        "\ttype=int,\n",
        "\tdefault=4, \n",
        "\thelp=\"sample negative items for training\")\n",
        "parser.add_argument(\"--test_num_ng\", \n",
        "\ttype=int,\n",
        "\tdefault=99, \n",
        "\thelp=\"sample part of negative items for testing\")\n",
        "parser.add_argument(\"--out\", \n",
        "\tdefault=True,\n",
        "\thelp=\"save model or not\")\n",
        "parser.add_argument(\"--gpu\", \n",
        "\ttype=str,\n",
        "\tdefault=\"0\",  \n",
        "\thelp=\"gpu card ID\")\n",
        "args = parser.parse_args()"
      ],
      "metadata": {
        "id": "Xz6BBB-XGVzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "e5tIFUkXGiXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################## PREPARE DATASET ##########################\n",
        "train_data, test_data, user_num ,item_num, train_mat = data_utils.load_all()\n",
        "\n",
        "# construct the train and test datasets\n",
        "train_dataset = NCFData(\n",
        "\t\ttrain_data, item_num, train_mat, args.num_ng, True)\n",
        "test_dataset = NCFData(\n",
        "\t\ttest_data, item_num, train_mat, 0, False)\n",
        "train_loader = data.DataLoader(train_dataset,\n",
        "\t\tbatch_size=args.batch_size, shuffle=True, num_workers=4)\n",
        "test_loader = data.DataLoader(test_dataset,\n",
        "\t\tbatch_size=args.test_num_ng+1, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "l151tuOlGkK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################### CREATE MODEL #################################\n",
        "if config.model == 'NeuMF-pre':\n",
        "\tassert os.path.exists(config.GMF_model_path), 'lack of GMF model'\n",
        "\tassert os.path.exists(config.MLP_model_path), 'lack of MLP model'\n",
        "\tGMF_model = torch.load(config.GMF_model_path)\n",
        "\tMLP_model = torch.load(config.MLP_model_path)\n",
        "else:\n",
        "\tGMF_model = None\n",
        "\tMLP_model = None\n",
        "\n",
        "model = NCF(user_num, item_num, args.factor_num, args.num_layers, \n",
        "\t\t\t\t\t\targs.dropout, config.model, GMF_model, MLP_model)\n",
        "model.cuda()\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "if config.model == 'NeuMF-pre':\n",
        "\toptimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
        "else:\n",
        "\toptimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "# writer = SummaryWriter() # for visualization"
      ],
      "metadata": {
        "id": "P8wnQqwyGmRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCDEhRipER6I"
      },
      "outputs": [],
      "source": [
        "########################### TRAINING #####################################\n",
        "count, best_hr = 0, 0\n",
        "for epoch in range(args.epochs):\n",
        "\tmodel.train() # Enable dropout (if have).\n",
        "\tstart_time = time.time()\n",
        "\ttrain_loader.dataset.ng_sample()\n",
        "\n",
        "\tfor user, item, label in train_loader:\n",
        "\t\tuser = user.cuda()\n",
        "\t\titem = item.cuda()\n",
        "\t\tlabel = label.float().cuda()\n",
        "\n",
        "\t\tmodel.zero_grad()\n",
        "\t\tprediction = model(user, item)\n",
        "\t\tloss = loss_function(prediction, label)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\t# writer.add_scalar('data/loss', loss.item(), count)\n",
        "\t\tcount += 1\n",
        "\n",
        "\tmodel.eval()\n",
        "\tHR, NDCG = metrics(model, test_loader, args.top_k)\n",
        "\n",
        "\telapsed_time = time.time() - start_time\n",
        "\tprint(\"The time elapse of epoch {:03d}\".format(epoch) + \" is: \" + \n",
        "\t\t\ttime.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n",
        "\tprint(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n",
        "\n",
        "\tif HR > best_hr:\n",
        "\t\tbest_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n",
        "\t\tif args.out:\n",
        "\t\t\tif not os.path.exists(config.model_path):\n",
        "\t\t\t\tos.mkdir(config.model_path)\n",
        "\t\t\ttorch.save(model, \n",
        "\t\t\t\t'{}{}.pth'.format(config.model_path, config.model))\n",
        "\n",
        "print(\"End. Best epoch {:03d}: HR = {:.3f}, NDCG = {:.3f}\".format(\n",
        "\t\t\t\t\t\t\t\t\tbest_epoch, best_hr, best_ndcg))\n"
      ]
    }
  ]
}